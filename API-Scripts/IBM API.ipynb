{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import SpeechToTextV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "speech_to_text_api_key = None\n",
    "speech_to_text_authenticator = IAMAuthenticator(speech_to_text_api_key)\n",
    "speech_to_text = SpeechToTextV1(authenticator=speech_to_text_authenticator)\n",
    "speech_to_text.set_service_url('https://stream.watsonplatform.net/speech-to-text/api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rate\": 16000,\n",
      "  \"name\": \"en-US_BroadbandModel\",\n",
      "  \"language\": \"en-US\",\n",
      "  \"url\": \"https://stream.watsonplatform.net/speech-to-text/api/v1/models/en-US_BroadbandModel\",\n",
      "  \"supported_features\": {\n",
      "    \"custom_language_model\": true,\n",
      "    \"speaker_labels\": true\n",
      "  },\n",
      "  \"description\": \"US English broadband model.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "speech_to_text_model = speech_to_text.get_model('en-US_BroadbandModel').get_result()\n",
    "print(json.dumps(speech_to_text_model, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accepted definition of creativity is production of something original and useful and it is commonly thought that creativity occurs on the right side of the brain and the arts play an important role in enhancing it but according to new research creativity isn't about freedom from concrete facts \n"
     ]
    }
   ],
   "source": [
    "with open('./audio-dataset/audio/00.wav', 'rb') as audio_file:\n",
    "    response = speech_to_text.recognize(audio=audio_file, content_type='audio/wav', model='en-US_BroadbandModel', smart_formatting=True).get_result()\n",
    "    transcript = ''.join([sentence['alternatives'][0]['transcript'] for sentence in response['results']])\n",
    "    print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import VisualRecognitionV3\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "visual_recognition_api_key = None\n",
    "visual_recognition_authenticator = IAMAuthenticator(visual_recognition_api_key)\n",
    "visual_recognition = VisualRecognitionV3(version='2018-03-19', authenticator=visual_recognition_authenticator)\n",
    "visual_recognition.set_service_url('https://gateway.watsonplatform.net/visual-recognition/api')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"classifiers\": [\n",
      "        {\n",
      "          \"classifier_id\": \"default\",\n",
      "          \"name\": \"default\",\n",
      "          \"classes\": [\n",
      "            {\n",
      "              \"class\": \"olive color\",\n",
      "              \"score\": 0.973\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"image\": \"fruitbowl.jpg\"\n",
      "    }\n",
      "  ],\n",
      "  \"images_processed\": 1,\n",
      "  \"custom_classes\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./fruitbowl.jpg', 'rb') as images_file:\n",
    "    classes = visual_recognition.classify(images_file=images_file, threshold='0.8', owners=['IBM']).get_result()\n",
    "    print(json.dumps(classes, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"classifiers\": [\n",
      "        {\n",
      "          \"classifier_id\": \"food\",\n",
      "          \"name\": \"food\",\n",
      "          \"classes\": [\n",
      "            {\n",
      "              \"class\": \"apple\",\n",
      "              \"score\": 0.572,\n",
      "              \"type_hierarchy\": \"/fruit/accessory fruit/apple\"\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"accessory fruit\",\n",
      "              \"score\": 0.572\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"fruit\",\n",
      "              \"score\": 0.805\n",
      "            },\n",
      "            {\n",
      "              \"class\": \"banana\",\n",
      "              \"score\": 0.5,\n",
      "              \"type_hierarchy\": \"/fruit/banana\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"image\": \"fruitbowl.jpg\"\n",
      "    }\n",
      "  ],\n",
      "  \"images_processed\": 1,\n",
      "  \"custom_classes\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./fruitbowl.jpg', 'rb') as images_file:\n",
    "    classes = visual_recognition.classify(images_file=images_file, classifier_ids=['food'], owners=['IBM']).get_result()\n",
    "    print(json.dumps(classes, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"images\": [\n",
      "    {\n",
      "      \"classifiers\": [\n",
      "        {\n",
      "          \"classifier_id\": \"explicit\",\n",
      "          \"name\": \"explicit\",\n",
      "          \"classes\": [\n",
      "            {\n",
      "              \"class\": \"not explicit\",\n",
      "              \"score\": 0.996\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"image\": \"fruitbowl.jpg\"\n",
      "    }\n",
      "  ],\n",
      "  \"images_processed\": 1,\n",
      "  \"custom_classes\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./fruitbowl.jpg', 'rb') as images_file:\n",
    "    classes = visual_recognition.classify(images_file=images_file, classifier_ids=['explicit'], owners=['IBM']).get_result()\n",
    "    print(json.dumps(classes, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
