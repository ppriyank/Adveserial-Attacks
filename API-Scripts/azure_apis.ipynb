{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content Moderation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Celebrity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognizing first result...\n",
      "Speech Recognition canceled: CancellationReason.Error\n",
      "Error details: WebSocket Upgrade failed with an authentication error (401). Please check for correct subscription key (or authorization token) and region name. SessionId: 278e547c85b44cebbeeb31d448a36733\n"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "speech_key, service_region = \"485a1f34-41bb-4d1c-bf60-30a57d11edee\", \"eastus\"\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
    "\n",
    "audio_filename = \"D:/NYU_MS/Sem3/CloudML/Adveserial-Attacks/audio-dataset/audio/00.wav\"\n",
    "audio_input = speechsdk.AudioConfig(filename=audio_filename)\n",
    "\n",
    "# Creates a recognizer with the given settings\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)\n",
    "\n",
    "print(\"Recognizing first result...\")\n",
    "\n",
    "\n",
    "# Starts speech recognition, and returns after a single utterance is recognized. The end of a\n",
    "# single utterance is determined by listening for silence at the end or until a maximum of 15\n",
    "# seconds of audio is processed.  The task returns the recognition text as result. \n",
    "# recognize_once() -> only a single utterance, it is suitable only for single shot recognition like command or query. \n",
    "# long-running multi-utterance recognition -> start_continuous_recognition() instead.\n",
    "result = speech_recognizer.recognize_once()\n",
    "\n",
    "# Result.\n",
    "if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "    print(\"Recognized: {}\".format(result.text))\n",
    "elif result.reason == speechsdk.ResultReason.NoMatch:\n",
    "    print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        print(\"Error details: {}\".format(cancellation_details.error_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
